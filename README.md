# A list of projects related to data 

This is a selection of projects I've worked on in the past related to data. The images link to the project sites. Note that this only includes *public* projects. A good, general thought piece of mine is [*Data as culture: how will we live in a data driven society?*](https://www.statslife.org.uk/opinion/1848-data-as-culture-how-will-we-live-in-a-data-driven-society)

**Table of Contents**

Goes here, once I figured out how to make it automatically.

### _Show me the money_, a data project

In *Show me the money* I analysed the complete data of the three biggest peer-to-peer (P2P) platforms in the UK: Zopa, RateSetter, and Funding Circle. The data contains almost 14 million loan parts. It provided the most comprehensive snapshot of the UK P2P market at the time of publication. We gained high-profile media coverage for this story and have direct evidence of change in the peer-to-peer sector.

<a href="http://smtm.labs.theodi.org/" class="no-decor" target="_blank">
<img src="https://raw.githubusercontent.com/statshero/data-projects/master/assets/showmethemoney.png" alt="" width="529" height="295"></a>

`2013, peer-to-peer, R, analysis, visualisation, project management`


### _How open data can help shape the way we analyse electoral behaviour_, another data project

A joint project between  Deloitte and the Open Data Institute on how election data can help give insights into voting behaviour. I enjoyed this project a lot, as it was interesting, a fast turn-around and I got to apply various models among them [random forests](https://www.quora.com/How-does-randomization-in-a-random-forest-work).

<a href="http://www.theguardian.com/news/datablog/2014/jun/02/how-open-data-can-help-shape-the-way-we-analyse-electoral-behaviour" class="no-decor" target="_blank">
<img src="https://raw.githubusercontent.com/statshero/data-projects/master/assets/democratic-engagement.png" alt="" width="529" height="295"></a>

`2014, R, analysis, visualisation, elections`


### _What is a CSV? A case study of CSVs on data.gov.uk_, an elaborate blog post

A short project during my time at the Open Data Institute, where I analysed more than 20,000 links to CSV files on [data.gov.uk](http://data.gov.uk). Results: only around one third turned out to be machine-readable. A typical CSV is between 1kb-1mb in size and has around eight columns. And I got to play around with [Gephi](https://gephi.org/). 

<a href="https://theodi.org/blog/the-status-of-csvs-on-datagovuk" class="no-decor" target="_blank">
<img src="https://raw.githubusercontent.com/statshero/data-projects/master/assets/csv-study.png" alt="" width="529" height="295"></a>

`2014, R, analysis, CSV, study`

###  _A survey of the uses of quantified self_, a survey and presentation

The [presentation slides](https://github.com/londonqs/qs/blob/master/meetup-content/2014-02/Survey%20overview.pdf) give a brief overview about the findings. For me it was interesting to [play around with SPSS and R integration](https://github.com/statshero/qs-survey/), that is variable labels. There's also a nice integration with Google documents and R. I was particularly pleased when I reused code that was years old – and it worked.

<a href="https://github.com/londonqs/qs/blob/master/meetup-content/2014-02/Survey%20overview.pdf" class="no-decor" target="_blank">
<img src="https://raw.githubusercontent.com/statshero/data-projects/master/assets/qs-survey.png" alt="" width="529" height="295"></a>

`2014, quantified self, R, analysis, survey, presentation`

There is a lot more where this came from... Here is an example: a [book chapter](https://issuu.com/designacademy/docs/_05_stressedout_issuu/26).  

### _How to prioritise open data to drive global development_, a tool for global development

I designed the methodology and enjoyed classifying ~~case studies~~, ~~applications~~, *anecdata*. For each sector, we mapped out relevant datasets and examples of real-world open data applications. We then offer three goal options to help decision- and policy-makers select datasets to release as open data.

<a href="http://theodi.org/guides/prioritise-open-data-to-drive-global-development" class="no-decor" target="_blank">
<img src="https://raw.githubusercontent.com/statshero/data-projects/master/assets/prioritise-opendata.png" alt="" width="529" height="295"></a>

`2014, open data, report, spreadsheet, recommendation`


### The _anonymisation decision-making framework_, an online course

Together with the [UK Anonymisation Network](http://ukanon.net) and [Purple Guerrilla](https://www.linkedin.com/company/purple-guerrilla) I've managed and developed an online course as an introduction to anonymisation. The online learning aims to promote the decision-making framework and give data practitioners confidence when dealing with personal data.

<a href="http://theodi.github.io/ukan-course" class="no-decor" target="_blank">
<img src="https://raw.githubusercontent.com/statshero/data-projects/master/assets/ukan.png" alt="" width="529" height="295"></a>

`2015, anonymisation, governance, learning, project management, spreadsheet`

### Benchmarking open data automatically, a technical report

A high-level overview of if and how we can evaluate and rank countries, organisations and projects, based on how well they use open data in different ways. As open data becomes more widespread and useful, so does the need for effective ways to analyse it. 

<a href="https://theodi.org/guides/benchmarking-data-automatically" class="no-decor" target="_blank">
<img src="https://raw.githubusercontent.com/statshero/data-projects/master/assets/benchmarking.png" alt="" width="529" height="295"></a>

`2014, open data, benchmarking, report, recommendations`


### The _Open Rail Performance Index_, a failed study

An example of a failed study because we never managed to publish the results. It was titled *How the UK could gain up to £387 million per year* and then it got political. The upshot: I learned a lot about R, the train industry and the value of travel time savings. 

<a href="https://en.wikipedia.org/wiki/Self-censorship" target="_blank">
<img src="https://raw.githubusercontent.com/statshero/data-projects/master/assets/historic-passenger-numbers.png" alt="" width="880" height="220"></a>

`2014, open data, R, rail, benchmarking, report`


### Academic and boring technical stuff

* Making [fast consensus clustering in R](https://github.com/statshero/consensusclustering
) possible with speed improvements of x60. This is an extension for the R package `clusterCons`. More information about the package can be found [here](http://cran.r-project.org/web/packages/clusterCons/index.html). It has now been removed, so I'm not sure what's going on. 
* Atz, U. (2014). The tau of data: A new metric to assess the timeliness of data in catalogues. In _Conference for E-Democracy and Open Governement_ (p. 257). Available online at [http://project.opendatamonitor.eu/wp-content/uploads/dissemination/OpenDataMonitor_Publication_The-Tau-of-Data.pdf](http://project.opendatamonitor.eu/wp-content/uploads/dissemination/OpenDataMonitor_Publication_The-Tau-of-Data.pdf)
* Atz, U. (2013). Evaluating experience sampling of stress in a single-subject research design. _Personal and ubiquitous computing_, 17(4), 639-652. Available online at [http://ulrichatz.eu/docs/atz-2013-experience-sampling.pdf](http://ulrichatz.eu/docs/atz-2013-experience-sampling.pdf) 
* Enjoy the rabbit hole of econometrics in my Master's thesis: [Empirics in Biotechnology: How does public R&D support affect private R&D investments?](https://github.com/statshero/netzseite/raw/gh-pages/docs/diplomarbeit_biotech_ATZ.pdf)
* A tiny collection of [R scripts](https://gist.github.com/statshero), but I am really proud of `row-sample`, a function to make analysing a random subset easier.




### On data visualisation

* An **introduction to the history of visualisation** and many examples. Sadly it's hidden deep away on page 30 of an [OpenDataMonitor report](http://project.opendatamonitor.eu/wp-content/uploads/deliverable/OpenDataMonitor_611988_D2.3-Best-practice-visualisation,-dashboard-and-key-figures-report.pdf). I plan to make this more accessible in the future. 
* I run an **R course on visualisation**, in particular `ggplot2`. I think I'm not allowed to release the training material, so I err on the safe side.
* A vain, self-referential [visualisation of temperature levels of 10 000 days](https://github.com/statshero/Weather_timeseries_BZ/blob/master/cal%2010000%20days.pdf) for my 10 000th day alive. 
* [SCHEME_TUFTE](https://ideas.repec.org/c/boc/bocode/s457285.html): **Stata module** to provide a Tufte-inspired graphics scheme
* Some [templates](https://github.com/statshero/SPSS-tools) to make **SPSS charts** look more appealing


### Some more random fun projects, with data

* [A tutorial on how to import a HTML table into R](http://rpubs.com/statshero/opinion-polls). Actually, I find the visualisation part more interesting. 
* [Cleaning up](https://github.com/statshero/wine-cellar) the dataset from the [annual statement on the Government Wine Cellar](https://www.gov.uk/government/publications/annual-statement-on-the-government-wine-cellar-for-the-financial-year-2013-to-14). Not a glamorous job but someone has to do it.
* When I jumped on the train to comment on [Piketty's Capital](https://theodi.org/blog/pikettys-capital-changed-the-global-discussion-around-inequality-because-it-uses-great-data-now-make-it-open), I made some suggestions on how to make his charts better. For example, in the style of the Economist. 
* I run around ten workshops on anonymisation called *Save the Titanic* based on this [event](https://theodi.org/guides/save-the-titanic-handson-anonymisation-and-risk-control-of-publishing-open-data). Trust me when I say I know the **Titanic passenger data** inside-out.




